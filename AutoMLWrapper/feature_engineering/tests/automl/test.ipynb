{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "#### Klassen protecten\n",
    "```\n",
    "import AutoMLWrapper.automlwrapper as aw\n",
    "aw.Configuration.Configuration\n",
    "```\n",
    "\n",
    "#### Erweiterung um Bibliotheken\n",
    "-  @__library.setter\n",
    "    - a) Global/GlobalConfig.yaml\n",
    "        - lib-names\n",
    "        - type mappings\n",
    "    - b) directory durchsuchen \n",
    "- import in AutoMLWrapper anpassen\n",
    "- SEDAR automl.py config locations anpassen\n",
    "\n",
    "### custom proprocessing\n",
    "- typen checken\n",
    "- die wrapper könnten property methods implementieren, die die Rückgabe eines festen samples prüfen\n",
    "\n",
    "### custom parameters\n",
    "\n",
    "\n",
    "### 2+ problem types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-03 17:13:14.493299: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-03 17:13:14.993779: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mAutoMLWrapper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataSamples\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#from automlwrapper import AutoMLWrapper\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mAutoMLWrapper\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautomlwrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoMLWrapper, SedarDataLoader\n",
      "File \u001b[0;32m~/sedar-masterarbeit/sedar/sedar/automl/AutoMLWrapper/tests/DataSamples.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mnist\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWARNING: Keras not installed. Some functionalities might not be available.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/keras/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/keras/models/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/keras/engine/functional.py:24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv2\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m backend\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layout_map \u001b[38;5;28;01mas\u001b[39;00m layout_map_lib\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m module_util \u001b[38;5;28;01mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlazy_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LazyLoader \u001b[38;5;28;01mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/tensorflow/python/__init__.py:36\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtraceback\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow \u001b[38;5;28;01mas\u001b[39;00m _pywrap_tensorflow\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Bring in subpackages.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/tensorflow/python/pywrap_tensorflow.py:26\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m self_check\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# TODO(mdan): Cleanup antipattern: import for side effects.\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Perform pre-load sanity checks in order to produce a more actionable error.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mself_check\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreload_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     31\u001b[0m   \u001b[38;5;66;03m# This import is expected to fail if there is an explicit shared object\u001b[39;00m\n\u001b[1;32m     32\u001b[0m   \u001b[38;5;66;03m# dependency (with_framework_lib=true), since we do not need RTLD_GLOBAL.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/tensorflow/python/platform/self_check.py:63\u001b[0m, in \u001b[0;36mpreload_check\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     51\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find the DLL(s) \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m. TensorFlow requires that these DLLs \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbe installed in a directory that is named in your \u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124mPATH\u001b[39m\u001b[38;5;132;01m%%\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     57\u001b[0m           \u001b[38;5;241m%\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(missing))\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m   \u001b[38;5;66;03m# Load a library that performs CPU feature guard checking.  Doing this here\u001b[39;00m\n\u001b[1;32m     60\u001b[0m   \u001b[38;5;66;03m# as a preload check makes it more likely that we detect any CPU feature\u001b[39;00m\n\u001b[1;32m     61\u001b[0m   \u001b[38;5;66;03m# incompatibilities before we trigger them (which would typically result in\u001b[39;00m\n\u001b[1;32m     62\u001b[0m   \u001b[38;5;66;03m# SIGILL).\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m   \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _pywrap_cpu_feature_guard\n\u001b[1;32m     64\u001b[0m   _pywrap_cpu_feature_guard\u001b[38;5;241m.\u001b[39mInfoAboutUnusedCPUFeatures()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import io\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from AutoMLWrapper.tests import DataSamples\n",
    "\n",
    "#from automlwrapper import AutoMLWrapper\n",
    "from AutoMLWrapper.automlwrapper import AutoMLWrapper, SedarDataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ALL = 0\n",
    "UPLOAD_ALL = 0\n",
    "\n",
    "RUN_KERAS = 1\n",
    "UPLOAD_KERAS = 0\n",
    "\n",
    "RUN_SKLEARN = 0\n",
    "UPLOAD_SKLEARN = 0\n",
    "\n",
    "RUN_GLUON = 0\n",
    "UPLOAD_GLUON = 0\n",
    "\n",
    "user_hp = {'epochs':2, 'time_limit': 40, 'memory_limit':7000, 'testtest': 123, 'num_trials': 1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW = 0\n",
    "\n",
    "if MLFLOW:\n",
    "    \n",
    "    # #experiment_id = mlflow.create_experiment('test_automl', artifact_location='/home/mibbels/sedar-masterarbeit/sedar/sedar/automl/tmp/artifacts')\n",
    "    \n",
    "    experiment_id = 5\n",
    "    remote_server_uri = \"http://127.0.0.1:6798\"\n",
    "    mlflow.set_tracking_uri(remote_server_uri) \n",
    "    mlflow.set_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Bilddaten \"\"\"\n",
    "#mnist_byte_df = DataSamples.create_mnist_bytearray_df(label_col='label', n_samples=-1)\n",
    "shopee_path_df = DataSamples.create_shopee_df(is_bytearray = False, n_samples=-1)\n",
    "#mnist_tp = DataSamples.create_mnist_tuple(n_samples=-1)\n",
    "#leaf_df = DataSamples.create_leaf_df(n_samples=-1)\n",
    "\n",
    "coco_df = DataSamples.create_coco_motorbike_df(n_samples=-1)\n",
    "\n",
    "\"\"\" Textdaten \"\"\"\n",
    "#sentiment_df = DataSamples.create_sentiment_treebank_df(n_samples=-1)\n",
    "#mloc_df = DataSamples.create_mloc_df(n_samples=-1)\n",
    "\n",
    "\"\"\" Tabellendaten \"\"\"\n",
    "glass_df = DataSamples.create_glass_df()\n",
    "\n",
    "\"\"\" Timeseries \"\"\"\n",
    "#m4_df = DataSamples.create_m4_df(n_samples=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = AutoMLWrapper('autosklearn')\n",
    "ask.SetOutputDirectory('test/ask/2')\n",
    "\n",
    "if RUN_ALL or RUN_SKLEARN:\n",
    "    ask.Train(\n",
    "        train_data=glass_df,\n",
    "        target_column='Type',\n",
    "        task_type='classification',\n",
    "        data_type='tabular',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters=user_hp\n",
    "    )\n",
    "\n",
    "\n",
    "if UPLOAD_ALL or UPLOAD_SKLEARN:\n",
    "    print(ask.Output())\n",
    "    ask.MlflowUploadBest({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_dict = mlflow.get_run(\"a9da8f651413411db69af32c2445a011\")\n",
    "#print(run_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agl = AutoMLWrapper('autogluon')\n",
    "agl.SetOutputDirectory('test/agl/9')\n",
    "user_hp = {'preset':\"medium_quality\", 'time_limit': 10, 'num_bag_sets':2, 'verbisity':0}\n",
    "if RUN_ALL or RUN_GLUON: \n",
    "    pass\n",
    "    train, test = SedarDataLoader.split_train_test(glass_df)\n",
    "    #agl.AllowExtraHyperparameters({'fit' : ['num_bag_sets']})\n",
    "    agl.Train(\n",
    "         train_data=train,\n",
    "         validation_data=None,\n",
    "         target_column='Type',\n",
    "         data_type='tabular',\n",
    "         task_type='classification',        \n",
    "         problem_type='multiclass',\n",
    "         hyperparameters=user_hp\n",
    "    )\n",
    "ev = agl.Evaluate(test, target_column='Type')\n",
    "    \n",
    "if UPLOAD_ALL or UPLOAD_GLUON:\n",
    "    #agl._AutoMLWrapper__library._get_info_from_fit_summary(0)\n",
    "    agl.MlflowUploadBest({})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from test/akr/1/image_classifier/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mibbels/sedar-masterarbeit/sedar/sedar/automl/AutoMLWrapper/automlwrapper/SedarDataLoader.py:327: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array(images)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ================================================= \n",
      " AutoMLWrapper Warning:\n",
      "            \n",
      " The following hyperparameters were not found in the configuration files and were thus ignored: \n",
      "            \n",
      " {'memory_limit', 'testtest', 'time_limit'} \n",
      "            \n",
      " If you want to use these hyperparameters, set their names explicitly with wrapper.AllowExtraHyperparameters().\n",
      "            \n",
      " =================================================\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expect the data to ImageInput to be numerical, but got object.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m akr\u001b[38;5;241m.\u001b[39mSetOutputDirectory(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest/akr/1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m RUN_ALL \u001b[38;5;129;01mor\u001b[39;00m RUN_KERAS:\n\u001b[0;32m----> 5\u001b[0m     \u001b[43makr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshopee_path_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#validation_data=shopee_path_df,\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproblem_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmulticlass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_hp\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(akr\u001b[38;5;241m.\u001b[39mEvaluate(shopee_path_df))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m UPLOAD_ALL \u001b[38;5;129;01mor\u001b[39;00m UPLOAD_KERAS:\n",
      "File \u001b[0;32m~/sedar-masterarbeit/sedar/sedar/automl/AutoMLWrapper/automlwrapper/AutoMLWrapper.py:151\u001b[0m, in \u001b[0;36mAutoMLWrapper.Train\u001b[0;34m(self, train_data, validation_data, target_column, task_type, data_type, problem_type, hyperparameters)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_initialized:\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mInitialize(train_data, target_column, task_type, data_type, problem_type)\n\u001b[0;32m--> 151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sedar-masterarbeit/sedar/sedar/automl/AutoMLWrapper/automlwrapper/AutoKeras/AutoKerasWrapper.py:65\u001b[0m, in \u001b[0;36mAutoKerasWrapper._train_model\u001b[0;34m(self, data, val_data, target_column, user_hyperparameters)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_structured(data, val_data, target_column, user_hyperparameters)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_hyperparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sedar-masterarbeit/sedar/sedar/automl/AutoMLWrapper/automlwrapper/AutoKeras/AutoKerasWrapper.py:112\u001b[0m, in \u001b[0;36mAutoKerasWrapper._train_image\u001b[0;34m(self, data, val_data, target_column, user_hyperparameters)\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m ak\u001b[38;5;241m.\u001b[39mImageRegressor(\n\u001b[1;32m    107\u001b[0m         directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_path,\n\u001b[1;32m    108\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget_params_constructor_by_key(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImageRegressor\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[1;32m    109\u001b[0m     )\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_model_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_get_mlflow_details(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImageRegressor\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__log_model_type\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n\u001b[0;32m--> 112\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_tuple\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_params_fit_by_key\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImageClassifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclassification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mImageRegressor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregression\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m    117\u001b[0m \u001b[43m                                  \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/autokeras/tasks/image.py:165\u001b[0m, in \u001b[0;36mImageClassifier.fit\u001b[0;34m(self, x, y, epochs, callbacks, validation_split, validation_data, **kwargs)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    110\u001b[0m     x: Optional[types\u001b[38;5;241m.\u001b[39mDatasetType] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    119\u001b[0m ):\n\u001b[1;32m    120\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search for the best model and hyperparameters for the AutoModel.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \n\u001b[1;32m    122\u001b[0m \u001b[38;5;124;03m    It will search for the best model based on the performances on\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m            validation loss values and validation metrics values (if applicable).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 165\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/autokeras/auto_model.py:280\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_data:\n\u001b[1;32m    278\u001b[0m     validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 280\u001b[0m dataset, validation_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_to_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_analyze_data(dataset)\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_hyper_pipeline(dataset)\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/autokeras/auto_model.py:398\u001b[0m, in \u001b[0;36mAutoModel._convert_to_dataset\u001b[0;34m(self, x, y, validation_data, batch_size)\u001b[0m\n\u001b[1;32m    396\u001b[0m     x \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: x)\n\u001b[1;32m    397\u001b[0m     y \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x, y: y)\n\u001b[0;32m--> 398\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_adapt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    399\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adapt(y, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_heads, batch_size)\n\u001b[1;32m    400\u001b[0m dataset \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mzip((x, y))\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/autokeras/auto_model.py:311\u001b[0m, in \u001b[0;36mAutoModel._adapt\u001b[0;34m(self, dataset, hms, batch_size)\u001b[0m\n\u001b[1;32m    309\u001b[0m adapted \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m source, hm \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sources, hms):\n\u001b[0;32m--> 311\u001b[0m     source \u001b[38;5;241m=\u001b[39m \u001b[43mhm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_adapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapt\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    312\u001b[0m     adapted\u001b[38;5;241m.\u001b[39mappend(source)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(adapted) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/autokeras/engine/adapter.py:67\u001b[0m, in \u001b[0;36mAdapter.adapt\u001b[0;34m(self, dataset, batch_size)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madapt\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset, batch_size):\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check, convert and batch the dataset.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    # Arguments\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        tf.data.Dataset. The converted dataset.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_to_dataset(dataset, batch_size)\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/autokeras/adapters/input_adapters.py:46\u001b[0m, in \u001b[0;36mImageAdapter.check\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpect the data to ImageInput to be numpy.ndarray or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf.data.Dataset, but got \u001b[39m\u001b[38;5;132;01m{type}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m(x))\n\u001b[1;32m     44\u001b[0m     )\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(x\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mnumber):\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpect the data to ImageInput to be numerical, but got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{type}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     49\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Expect the data to ImageInput to be numerical, but got object."
     ]
    }
   ],
   "source": [
    "akr = AutoMLWrapper('autokeras')\n",
    "akr.SetOutputDirectory('test/akr/1')\n",
    "\n",
    "if RUN_ALL or RUN_KERAS:\n",
    "    akr.Train(\n",
    "        train_data=shopee_path_df,\n",
    "        #validation_data=shopee_path_df,\n",
    "        target_column='label',\n",
    "        task_type='classification',\n",
    "        data_type='image',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters=user_hp\n",
    "    )\n",
    "\n",
    "    print(akr.Evaluate(shopee_path_df))\n",
    "\n",
    "if UPLOAD_ALL or UPLOAD_KERAS:\n",
    "    print(akr.Output())\n",
    "    akr.MlflowUploadBest({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow\n",
    "~/miniconda3/envs/automl_env/bin/pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLFLOW:\n",
    "    df = df_glass.drop(columns=['Type'])\n",
    "    logged_model = 'runs:/a0337b9ecfe84e99b59ff3a9639f1ef6/model'\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "    #loaded_model.predict(test_data_byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEDAR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader TODO\n",
    "- sedar api raw sourcedata\n",
    "- sedar api get_all_images (image metadata)\n",
    "\n",
    "- query_sourcedata nur structured\n",
    "    - image\n",
    "    - unstructured\n",
    "    - semistructured\n",
    "\n",
    "- keras format\n",
    "\n",
    "# Ingestion\n",
    "- metadaten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-03 17:13:27.443901: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-03 17:13:29.117689: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "from sedarapi import SedarAPI\n",
    "from AutoMLWrapper.automlwrapper.SedarDataLoader import SedarDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabcl = [\"13b4787c3e454649aa05a4cd680edc37\", \"986f2e837ca44f3e8c0ee7d2dc0c4287\",\n",
    "          \"./data/sedar_raw/zip\", \"tabular\", \"classification\", \"Type\"]\n",
    "imseg = [\"13b4787c3e454649aa05a4cd680edc37\", \"324ea420125d4167a76151b62368c4ad\",\n",
    "          \"./data/sedar_raw/zip\", \"image\", \"segmentation\", None]\n",
    "imcl = [\"13b4787c3e454649aa05a4cd680edc37\", \"513c6b1ee46b478c8e0925a098d2f387\",\n",
    "          \"./data/sedar_raw/zip\", \"image\", \"classification\", None]\n",
    "\n",
    "from AutoMLWrapper.automlwrapper.SedarDataLoader import SedarDataLoader\n",
    "from sedarapi import SedarAPI\n",
    "\n",
    "\n",
    "def test_sedar_caafe(workspace_id, dataset_id, file_save_location, data_type, problem_type, target):\n",
    "    base_url = \"http://192.168.220.107:5000\"\n",
    "    email = \"admin\"\n",
    "    password = \"admin\"\n",
    "    sedar = SedarAPI(base_url)\n",
    "    sedar.connection.logger.setLevel(\"INFO\")\n",
    "    sedar.login(email, password)\n",
    "\n",
    "    DataLoader = SedarDataLoader(sedar)\n",
    "    DataLoader.CAAFEFeatureEngineering(\n",
    "        workspace_id, \n",
    "        dataset_id, \n",
    "        file_save_location,\n",
    "        data_type,\n",
    "        problem_type,\n",
    "        target,\n",
    "        dataset_description='No description',\n",
    "        iterations=1\n",
    "    )\n",
    "    \n",
    "test_sedar_caafe(*imseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SedarAPI-Logger:Login successful\n",
      "WARNING:SedarAPI-Logger:Component Apache Jena Fuseki is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Jupyter - SingleUser is not alive.\n",
      "WARNING:SedarAPI-Logger:Component WebVOWL is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Ingestion - Service is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Schema & Metadata - Service is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Continuation - Service is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Profiling - Service is not alive.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sedarapi.user.User at 0x7f0fe32cf2e0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"http://192.168.220.107:5000\"\n",
    "email = \"admin\"\n",
    "password = \"admin\"\n",
    "\n",
    "sedar = SedarAPI(base_url)\n",
    "sedar.connection.logger.setLevel(\"INFO\")\n",
    "sedar.login(email, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader = SedarDataLoader(sedar)\n",
    "\n",
    "DataLoader.query_data('13b4787c3e454649aa05a4cd680edc37', 'f9dd03fb472540dfa4fd740fb65eec2e', file_save_location='./tmp/data/gitter_trainv1')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader.zip_to_segmentation_df_gluon('./tmp/data/gitter_trainv1', './tmp/data/gitter_trainv1/unzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_id = '13b4787c3e454649aa05a4cd680edc37'\n",
    "dataset_id = '324ea420125d4167a76151b62368c4ad'\n",
    "\n",
    "# 986f2e837ca44f3e8c0ee7d2dc0c4287  - glass\n",
    "# b5b74391e41e4634a54d5cffa059663b - coco_22_train_v1 \n",
    "# 324ea420125d4167a76151b62368c4ad - gitter_train_v1\n",
    "# 513c6b1ee46b478c8e0925a098d2f387  - test classification 1 img each class\n",
    "\n",
    "DataLoader = SedarDataLoader(sedar)\n",
    "#loc = DataLoader.query_data(workspace_id, dataset_id, file_save_location='./data/sedar_raw/test')\n",
    "#X, y, mapping = DataLoader.zip_to_class_np_keras(loc[0], './data/sedar_raw/test/test_coco')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.scripts import tabular_metrics\n",
    "\n",
    "if 0:\n",
    "    DataLoader.CAAFEFeatureEngineering(\n",
    "        workspace_id, \n",
    "        '986f2e837ca44f3e8c0ee7d2dc0c4287', \n",
    "        file_save_location='./data/sedar_raw/test',\n",
    "        data_type='tabular',\n",
    "        problem_type='classification',\n",
    "        target='Type',\n",
    "        dataset_description='No description',\n",
    "        iterations=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'datataset_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m X_new, y_new \u001b[38;5;241m=\u001b[39m DataLoader\u001b[38;5;241m.\u001b[39mCAAFEFeatureEngineering(\n\u001b[1;32m      2\u001b[0m     workspace_id, \n\u001b[0;32m----> 3\u001b[0m     \u001b[43mdatataset_id\u001b[49m, \n\u001b[1;32m      4\u001b[0m     file_save_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/sedar_raw/test\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m      6\u001b[0m     data_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msegmentation\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      8\u001b[0m     dataset_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      9\u001b[0m     iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datataset_id' is not defined"
     ]
    }
   ],
   "source": [
    "X_new, y_new = DataLoader.CAAFEFeatureEngineering(\n",
    "    workspace_id, \n",
    "    datataset_id, \n",
    "    file_save_location='./data/sedar_raw/test',\n",
    "    target=None,\n",
    "    data_type='image',\n",
    "    task_type='segmentation',\n",
    "    dataset_description='',\n",
    "    iterations=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = DataLoader.zip_to_segmentation_np_keras(loc[0], './data/sedar_raw/test/test_seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CAAFE.caafe import CAAFEImageClassifier, CAAFEImageSegmentor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import keras\n",
    "\n",
    "    cifar10 = keras.datasets.cifar10\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "    # If you want to use the entire dataset as X and y\n",
    "    X = np.concatenate((X_train, X_test), axis=0, dtype=np.float32)\n",
    "    y = np.concatenate((y_train, y_test), axis=0, dtype=np.float32)\n",
    "\n",
    "    #X = X.reshape(X.shape[0], 28, 28, 1)\n",
    "    X = X[:1000]\n",
    "    y = y[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = \"gpt-3.5-turbo\"\n",
    "model = \"gpt-4\"\n",
    "caafe_clf = CAAFEImageClassifier(llm_model=model,\n",
    "                                 iterations=3,\n",
    "                                 )\n",
    "\n",
    "pred = caafe_clf.performance_before_run(X, y)\n",
    "acc = accuracy_score(pred, y)\n",
    "print(f'Accuracy before CAAFE {acc}')\n",
    "\n",
    "\n",
    "caafe_clf.fit_images(\n",
    "    X,\n",
    "    y,\n",
    "    dataset_description=\"This is the CIFAR10 dataset.\"\n",
    "    )\n",
    "\n",
    "pred = caafe_clf.predict(X)\n",
    "acc = accuracy_score(pred, y)\n",
    "print(f'Accuracy after CAAFE {acc}')\n",
    "\n",
    "X, y = caafe_clf.apply_code(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y = caafe_clf.apply_code(X, y)\n",
    "pred = caafe_clf.predict(X)\n",
    "acc = accuracy_score(pred, y)\n",
    "print(f'Accuracy after CAAFE {acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    ws = sedar.get_workspace('13b4787c3e454649aa05a4cd680edc37')\n",
    "    dataset = ws.get_dataset('288188f8c0344edf9f9d90a23b3c009b')\n",
    "  \n",
    "    try:\n",
    "       \n",
    "        success = dataset.delete()\n",
    "        if success:\n",
    "            print(\"Dataset deleted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./AutoMLWrapper/tests && python3 -m unittest TestAutoMLWrapper.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

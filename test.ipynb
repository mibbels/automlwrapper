{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "#### Klassen protecten\n",
    "```\n",
    "import AutoMLWrapper.automlwrapper as aw\n",
    "aw.Configuration.Configuration\n",
    "```\n",
    "\n",
    "#### Erweiterung um Bibliotheken\n",
    "-  @__library.setter\n",
    "    - a) Global/GlobalConfig.yaml\n",
    "        - lib-names\n",
    "        - type mappings\n",
    "    - b) directory durchsuchen \n",
    "- import in AutoMLWrapper anpassen\n",
    "- SEDAR automl.py config locations anpassen\n",
    "\n",
    "### custom proprocessing\n",
    "- typen checken\n",
    "- die wrapper könnten property methods implementieren, die die Rückgabe eines festen samples prüfen\n",
    "\n",
    "### custom parameters\n",
    "\n",
    "\n",
    "### 2+ problem types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 18:42:54.901687: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-21 18:42:54.965270: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-21 18:42:54.966379: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-21 18:42:56.125880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from AutoMLWrapper.tests import DataSamples\n",
    "\n",
    "#from automlwrapper import AutoMLWrapper\n",
    "from AutoMLWrapper.automlwrapper import AutoMLWrapper, SedarDataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ALL = 0\n",
    "UPLOAD_ALL = 0\n",
    "\n",
    "RUN_KERAS = 0\n",
    "UPLOAD_KERAS = 0\n",
    "\n",
    "RUN_SKLEARN = 0\n",
    "UPLOAD_SKLEARN = 0\n",
    "\n",
    "RUN_GLUON = 1\n",
    "UPLOAD_GLUON = 0\n",
    "\n",
    "user_hp = {'epochs':2, 'time_limit': 40, 'memory_limit':7000, 'testtest': 123, 'num_trials': 1,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW = 0\n",
    "\n",
    "if MLFLOW:\n",
    "    \n",
    "    # #experiment_id = mlflow.create_experiment('test_automl', artifact_location='/home/mibbels/sedar-masterarbeit/sedar/sedar/automl/tmp/artifacts')\n",
    "    \n",
    "    experiment_id = 5\n",
    "    remote_server_uri = \"http://127.0.0.1:6798\"\n",
    "    mlflow.set_tracking_uri(remote_server_uri) \n",
    "    mlflow.set_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Timeseries '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Bilddaten \"\"\"\n",
    "#mnist_byte_df = DataSamples.create_mnist_bytearray_df(label_col='label', n_samples=-1)\n",
    "shopee_path_df = DataSamples.create_shopee_df(is_bytearray = False, n_samples=-1)\n",
    "#mnist_tp = DataSamples.create_mnist_tuple(n_samples=-1)\n",
    "#leaf_df = DataSamples.create_leaf_df(n_samples=-1)\n",
    "\n",
    "coco_df = DataSamples.create_coco_motorbike_df(n_samples=-1)\n",
    "\n",
    "\"\"\" Textdaten \"\"\"\n",
    "#sentiment_df = DataSamples.create_sentiment_treebank_df(n_samples=-1)\n",
    "#mloc_df = DataSamples.create_mloc_df(n_samples=-1)\n",
    "\n",
    "\"\"\" Tabellendaten \"\"\"\n",
    "glass_df = DataSamples.create_glass_df()\n",
    "\n",
    "\"\"\" Timeseries \"\"\"\n",
    "#m4_df = DataSamples.create_m4_df(n_samples=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = AutoMLWrapper('autosklearn')\n",
    "ask.SetOutputDirectory('test/ask/2')\n",
    "\n",
    "if RUN_ALL or RUN_SKLEARN:\n",
    "    ask.Train(\n",
    "        train_data=glass_df,\n",
    "        target_column='Type',\n",
    "        task_type='classification',\n",
    "        data_type='tabular',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters=user_hp\n",
    "    )\n",
    "\n",
    "\n",
    "if UPLOAD_ALL or UPLOAD_SKLEARN:\n",
    "    print(ask.Output())\n",
    "    ask.MlflowUploadBest({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_dict = mlflow.get_run(\"a9da8f651413411db69af32c2445a011\")\n",
    "#print(run_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"test/agl/9\"\n",
      "Presets specified: ['medium_quality']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 10s\n",
      "AutoGluon will save models to \"test/agl/9\"\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.0.0\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP PVE 5.15.102-1 (2023-03-14T13:48Z)\n",
      "CPU Count:          8\n",
      "Memory Avail:       38.89 GB / 62.50 GB (62.2%)\n",
      "Disk Space Avail:   21.31 GB / 251.86 GB (8.5%)\n",
      "===================================================\n",
      "Train Data Rows:    171\n",
      "Train Data Columns: 9\n",
      "Label Column:       Type\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 7 to avoid cutting too many classes.\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    39826.38 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['RI', 'Na', 'Mg', 'Al', 'Si', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['RI', 'Na', 'Mg', 'Al', 'Si', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Warning: use_bag_holdout=True, but bagged mode is not enabled. use_bag_holdout will be ignored.\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 136, Val Rows: 35\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 9.94s of the 9.94s of remaining time.\n",
      "\t0.6286\t = Validation score   (accuracy)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 9.92s of the 9.91s of remaining time.\n",
      "\t0.6857\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 9.89s of the 9.89s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetFastAI to fail during training... Skipping this model.\n",
      "\t\t\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in _calculate_total_resources\n",
      "    assert system_num_cpus >= num_cpus\n",
      "AssertionError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ================================================= \n",
      " AutoMLWrapper Warning:\n",
      "            \n",
      " The following hyperparameters were not found in the configuration files and were thus ignored: \n",
      "            \n",
      " {'verbisity', 'num_bag_sets'} \n",
      "            \n",
      " If you want to use these hyperparameters, set their names explicitly with wrapper.AllowExtraHyperparameters().\n",
      "            \n",
      " =================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitting model: LightGBMXT ... Training model for up to 9.38s of the 9.38s of remaining time.\n",
      "\tWarning: Exception caused LightGBMXT to fail during training... Skipping this model.\n",
      "\t\t\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in _calculate_total_resources\n",
      "    assert system_num_cpus >= num_cpus\n",
      "AssertionError\n",
      "Fitting model: LightGBM ... Training model for up to 9.01s of the 9.01s of remaining time.\n",
      "\tWarning: Exception caused LightGBM to fail during training... Skipping this model.\n",
      "\t\t\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in _calculate_total_resources\n",
      "    assert system_num_cpus >= num_cpus\n",
      "AssertionError\n",
      "Fitting model: RandomForestGini ... Training model for up to 8.56s of the 8.56s of remaining time.\n",
      "\t0.7714\t = Validation score   (accuracy)\n",
      "\t0.89s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ... Training model for up to 7.58s of the 7.58s of remaining time.\n",
      "\t0.8\t = Validation score   (accuracy)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 6.58s of the 6.58s of remaining time.\n",
      "\tWarning: Exception caused CatBoost to fail during training... Skipping this model.\n",
      "\t\t\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in _calculate_total_resources\n",
      "    assert system_num_cpus >= num_cpus\n",
      "AssertionError\n",
      "Fitting model: ExtraTreesGini ... Training model for up to 6.02s of the 6.02s of remaining time.\n",
      "\t0.8\t = Validation score   (accuracy)\n",
      "\t0.87s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ... Training model for up to 5.05s of the 5.05s of remaining time.\n",
      "\t0.7714\t = Validation score   (accuracy)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 4.12s of the 4.12s of remaining time.\n",
      "\tWarning: Exception caused XGBoost to fail during training... Skipping this model.\n",
      "\t\t\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in _calculate_total_resources\n",
      "    assert system_num_cpus >= num_cpus\n",
      "AssertionError\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 3.53s of the 3.52s of remaining time.\n",
      "\tWarning: Exception caused NeuralNetTorch to fail during training... Skipping this model.\n",
      "\t\t\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in _calculate_total_resources\n",
      "    assert system_num_cpus >= num_cpus\n",
      "AssertionError\n",
      "Fitting model: LightGBMLarge ... Training model for up to 3.03s of the 3.03s of remaining time.\n",
      "\tWarning: Exception caused LightGBMLarge to fail during training... Skipping this model.\n",
      "\t\t\n",
      "Detailed Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1817, in _train_and_save\n",
      "    model = self._train_single(X, y, model, X_val, y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 1763, in _train_single\n",
      "    model = model.fit(X=X, y=y, X_val=X_val, y_val=y_val, total_resources=total_resources, **model_fit_kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 846, in fit\n",
      "    kwargs = self._preprocess_fit_args(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 527, in _preprocess_fit_args\n",
      "    kwargs = self._preprocess_fit_resources(**kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 758, in _preprocess_fit_resources\n",
      "    return self._calculate_total_resources(silent=silent, total_resources=total_resources, parallel_hpo=parallel_hpo, **kwargs)\n",
      "  File \"/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 696, in _calculate_total_resources\n",
      "    assert system_num_cpus >= num_cpus\n",
      "AssertionError\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 9.94s of the 2.59s of remaining time.\n",
      "\tEnsemble Weights: {'RandomForestEntr': 0.5, 'ExtraTreesEntr': 0.5}\n",
      "\t0.8571\t = Validation score   (accuracy)\n",
      "\t0.25s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 7.68s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"test/agl/9\")\n"
     ]
    }
   ],
   "source": [
    "agl = AutoMLWrapper('autogluon')\n",
    "agl.SetOutputDirectory('test/agl/9')\n",
    "user_hp = {'preset':\"medium_quality\", 'time_limit': 10, 'num_bag_sets':2, 'verbisity':0}\n",
    "if RUN_ALL or RUN_GLUON: \n",
    "    pass\n",
    "    train, test = SedarDataLoader.split_train_test(glass_df)\n",
    "    #agl.AllowExtraHyperparameters({'fit' : ['num_bag_sets']})\n",
    "    agl.Train(\n",
    "         train_data=train,\n",
    "         validation_data=None,\n",
    "         target_column='Type',\n",
    "         data_type='tabular',\n",
    "         task_type='classification',        \n",
    "         problem_type='multiclass',\n",
    "         hyperparameters=user_hp\n",
    "    )\n",
    "    \n",
    "if UPLOAD_ALL or UPLOAD_GLUON:\n",
    "    #agl._AutoMLWrapper__library._get_info_from_fit_summary(0)\n",
    "    agl.MlflowUploadBest({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unable to coerce to Series, length must be 10: given 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ev \u001b[38;5;241m=\u001b[39m \u001b[43magl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEvaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sedar-masterarbeit/sedar/sedar/automl/AutoMLWrapper/automlwrapper/AutoMLWrapper.py:158\u001b[0m, in \u001b[0;36mAutoMLWrapper.Evaluate\u001b[0;34m(self, test_data, target_column, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__library \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m before \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluate\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 158\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__library\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__library\u001b[38;5;241m.\u001b[39meval_output\n",
      "File \u001b[0;32m~/sedar-masterarbeit/sedar/sedar/automl/AutoMLWrapper/automlwrapper/AutoGluon/AutoGluonWrapper.py:219\u001b[0m, in \u001b[0;36mAutoGluonWrapper._evaluate_model\u001b[0;34m(self, test_data, target_column, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mZero-shot models will not be evaluated. The predictions fromtraining have been returned.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_output\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mevaluate(\n\u001b[0;32m--> 219\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_preprocessing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    221\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/pandas/core/arraylike.py:242\u001b[0m, in \u001b[0;36mOpsMixin.__pow__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__pow__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__pow__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/pandas/core/frame.py:7455\u001b[0m, in \u001b[0;36mDataFrame._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   7452\u001b[0m axis: Literal[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# only relevant for Series other case\u001b[39;00m\n\u001b[1;32m   7453\u001b[0m other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mmaybe_prepare_scalar_for_op(other, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape[axis],))\n\u001b[0;32m-> 7455\u001b[0m \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign_method_FRAME\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   7457\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_frame_op(other, op, axis\u001b[38;5;241m=\u001b[39maxis)\n\u001b[1;32m   7458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(new_data)\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/pandas/core/ops/__init__.py:306\u001b[0m, in \u001b[0;36malign_method_FRAME\u001b[0;34m(left, right, axis, flex, level)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    303\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to coerce list of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(right[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m to Series/DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    304\u001b[0m         )\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;66;03m# GH17901\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     right \u001b[38;5;241m=\u001b[39m \u001b[43mto_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flex \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, ABCDataFrame):\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m left\u001b[38;5;241m.\u001b[39m_indexed_same(right):\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/pandas/core/ops/__init__.py:252\u001b[0m, in \u001b[0;36malign_method_FRAME.<locals>.to_series\u001b[0;34m(right)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(left\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(right):\n\u001b[0;32m--> 252\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    253\u001b[0m             msg\u001b[38;5;241m.\u001b[39mformat(req_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(left\u001b[38;5;241m.\u001b[39mcolumns), given_len\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(right))\n\u001b[1;32m    254\u001b[0m         )\n\u001b[1;32m    255\u001b[0m     right \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_constructor_sliced(right, index\u001b[38;5;241m=\u001b[39mleft\u001b[38;5;241m.\u001b[39mcolumns, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m right\n",
      "\u001b[0;31mValueError\u001b[0m: Unable to coerce to Series, length must be 10: given 0"
     ]
    }
   ],
   "source": [
    "ev = agl.Evaluate(test, target_column='Type')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "akr = AutoMLWrapper('autokeras')\n",
    "akr.SetOutputDirectory('test/akr/1')\n",
    "\n",
    "if RUN_ALL or RUN_KERAS:\n",
    "    akr.Train(\n",
    "        train_data=shopee_path_df,\n",
    "        #validation_data=shopee_path_df,\n",
    "        target_column='label',\n",
    "        task_type='classification',\n",
    "        data_type='image',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters=user_hp\n",
    "    )\n",
    "\n",
    "    print(akr.Evaluate(shopee_path_df))\n",
    "\n",
    "if UPLOAD_ALL or UPLOAD_KERAS:\n",
    "    print(akr.Output())\n",
    "    akr.MlflowUploadBest({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow\n",
    "~/miniconda3/envs/automl_env/bin/pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MLFLOW:\n",
    "    df = df_glass.drop(columns=['Type'])\n",
    "    logged_model = 'runs:/a0337b9ecfe84e99b59ff3a9639f1ef6/model'\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "    #loaded_model.predict(test_data_byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEDAR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader TODO\n",
    "- sedar api raw sourcedata\n",
    "- sedar api get_all_images (image metadata)\n",
    "\n",
    "- query_sourcedata nur structured\n",
    "    - image\n",
    "    - unstructured\n",
    "    - semistructured\n",
    "\n",
    "- keras format\n",
    "\n",
    "# Ingestion\n",
    "- metadaten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sedarapi import SedarAPI\n",
    "from AutoMLWrapper.automlwrapper.SedarDataLoader import SedarDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabcl = [\"13b4787c3e454649aa05a4cd680edc37\", \"986f2e837ca44f3e8c0ee7d2dc0c4287\",\n",
    "          \"./data/sedar_raw/zip\", \"tabular\", \"classification\", \"Type\"]\n",
    "imseg = [\"13b4787c3e454649aa05a4cd680edc37\", \"324ea420125d4167a76151b62368c4ad\",\n",
    "          \"./data/sedar_raw/zip\", \"image\", \"segmentation\", None]\n",
    "imcl = [\"13b4787c3e454649aa05a4cd680edc37\", \"513c6b1ee46b478c8e0925a098d2f387\",\n",
    "          \"./data/sedar_raw/zip\", \"image\", \"classification\", None]\n",
    "\n",
    "from AutoMLWrapper.automlwrapper.SedarDataLoader import SedarDataLoader\n",
    "from sedarapi import SedarAPI\n",
    "\n",
    "\n",
    "def test_sedar_caafe(workspace_id, dataset_id, file_save_location, data_type, problem_type, target):\n",
    "    base_url = \"http://192.168.220.107:5000\"\n",
    "    email = \"admin\"\n",
    "    password = \"admin\"\n",
    "    sedar = SedarAPI(base_url)\n",
    "    sedar.connection.logger.setLevel(\"INFO\")\n",
    "    sedar.login(email, password)\n",
    "\n",
    "    DataLoader = SedarDataLoader(sedar)\n",
    "    DataLoader.CAAFEFeatureEngineering(\n",
    "        workspace_id, \n",
    "        dataset_id, \n",
    "        file_save_location,\n",
    "        data_type,\n",
    "        problem_type,\n",
    "        target,\n",
    "        dataset_description='No description',\n",
    "        iterations=1\n",
    "    )\n",
    "    \n",
    "test_sedar_caafe(*imseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://192.168.220.107:5000\"\n",
    "email = \"admin\"\n",
    "password = \"admin\"\n",
    "\n",
    "sedar = SedarAPI(base_url)\n",
    "sedar.connection.logger.setLevel(\"INFO\")\n",
    "sedar.login(email, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader = SedarDataLoader(sedar)\n",
    "\n",
    "DataLoader.query_data('13b4787c3e454649aa05a4cd680edc37', 'f9dd03fb472540dfa4fd740fb65eec2e', file_save_location='./tmp/data/gitter_trainv1')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader.zip_to_segmentation_df_gluon('./tmp/data/gitter_trainv1', './tmp/data/gitter_trainv1/unzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_id = '13b4787c3e454649aa05a4cd680edc37'\n",
    "dataset_id = '324ea420125d4167a76151b62368c4ad'\n",
    "\n",
    "# 986f2e837ca44f3e8c0ee7d2dc0c4287  - glass\n",
    "# b5b74391e41e4634a54d5cffa059663b - coco_22_train_v1 \n",
    "# 324ea420125d4167a76151b62368c4ad - gitter_train_v1\n",
    "# 513c6b1ee46b478c8e0925a098d2f387  - test classification 1 img each class\n",
    "\n",
    "DataLoader = SedarDataLoader(sedar)\n",
    "#loc = DataLoader.query_data(workspace_id, dataset_id, file_save_location='./data/sedar_raw/test')\n",
    "#X, y, mapping = DataLoader.zip_to_class_np_keras(loc[0], './data/sedar_raw/test/test_coco')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.scripts import tabular_metrics\n",
    "\n",
    "if 0:\n",
    "    DataLoader.CAAFEFeatureEngineering(\n",
    "        workspace_id, \n",
    "        '986f2e837ca44f3e8c0ee7d2dc0c4287', \n",
    "        file_save_location='./data/sedar_raw/test',\n",
    "        data_type='tabular',\n",
    "        problem_type='classification',\n",
    "        target='Type',\n",
    "        dataset_description='No description',\n",
    "        iterations=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataLoader.CAAFEFeatureEngineering(\n",
    "    workspace_id, \n",
    "    '324ea420125d4167a76151b62368c4ad', \n",
    "    file_save_location='./data/sedar_raw/test',\n",
    "    data_type='image',\n",
    "    problem_type='segmentation',\n",
    "    dataset_description='No description',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = DataLoader.zip_to_segmentation_np_keras(loc[0], './data/sedar_raw/test/test_seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from CAAFE.caafe import CAAFEImageClassifier, CAAFEImageSegmentor\n",
    "from sklearn.metrics import accuracy_score\n",
<<<<<<< HEAD
    "import openai\n",
    "\n"
=======
    "import openai\n"
>>>>>>> 522cde8 (eval)
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import keras\n",
    "\n",
    "    cifar10 = keras.datasets.cifar10\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "    # If you want to use the entire dataset as X and y\n",
    "    X = np.concatenate((X_train, X_test), axis=0, dtype=np.float32)\n",
    "    y = np.concatenate((y_train, y_test), axis=0, dtype=np.float32)\n",
    "\n",
    "    #X = X.reshape(X.shape[0], 28, 28, 1)\n",
    "    X = X[:1000]\n",
    "    y = y[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = \"gpt-3.5-turbo\"\n",
    "model = \"gpt-4\"\n",
    "caafe_clf = CAAFEImageClassifier(llm_model=model,\n",
    "                                 iterations=3,\n",
    "                                 )\n",
    "\n",
    "pred = caafe_clf.performance_before_run(X, y)\n",
    "acc = accuracy_score(pred, y)\n",
    "print(f'Accuracy before CAAFE {acc}')\n",
    "\n",
    "\n",
    "caafe_clf.fit_images(\n",
    "    X,\n",
    "    y,\n",
    "    dataset_description=\"This is the CIFAR10 dataset.\"\n",
    "    )\n",
    "\n",
    "pred = caafe_clf.predict(X)\n",
    "acc = accuracy_score(pred, y)\n",
    "print(f'Accuracy after CAAFE {acc}')\n",
    "\n",
    "X, y = caafe_clf.apply_code(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, y = caafe_clf.apply_code(X, y)\n",
    "pred = caafe_clf.predict(X)\n",
    "acc = accuracy_score(pred, y)\n",
    "print(f'Accuracy after CAAFE {acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 0:\n",
    "    ws = sedar.get_workspace('13b4787c3e454649aa05a4cd680edc37')\n",
    "    dataset = ws.get_dataset('288188f8c0344edf9f9d90a23b3c009b')\n",
    "  \n",
    "    try:\n",
    "       \n",
    "        success = dataset.delete()\n",
    "        if success:\n",
    "            print(\"Dataset deleted successfully.\")\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ./AutoMLWrapper/tests && python3 -m unittest TestAutoMLWrapper.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

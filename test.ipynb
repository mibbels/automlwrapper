{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "#### Klassen protecten\n",
    "```\n",
    "import AutoMLWrapper.automlwrapper as aw\n",
    "aw.Configuration.Configuration\n",
    "```\n",
    "\n",
    "#### Erweiterung um Bibliotheken\n",
    "-  @__library.setter\n",
    "    - a) Global/GlobalConfig.yaml\n",
    "        - lib-names\n",
    "        - type mappings\n",
    "    - b) directory durchsuchen \n",
    "- import in AutoMLWrapper anpassen\n",
    "- SEDAR automl.py config locations anpassen\n",
    "\n",
    "### custom proprocessing\n",
    "- typen checken\n",
    "- die wrapper könnten property methods implementieren, die die Rückgabe eines festen samples prüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-11-25 13:47:12.233917: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-25 13:47:12.799412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-25 13:47:12.799488: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-11-25 13:47:12.799495: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#from automlwrapper import AutoMLWrapper\n",
    "from AutoMLWrapper.automlwrapper import AutoMLWrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/glass.csv')\n",
    "user_hp = {'num_trials': 10, 'time_limit': 40, 'testtest': 123}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ask = AutoMLWrapper('autosklearn')\n",
    "ask.SetOutputDirectory('test/ask1')\n",
    "\n",
    "if 0:\n",
    "    ask.Train(data=df, target_column='Type',\n",
    "        task_type='classification',\n",
    "        data_type='tabular',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters=user_hp\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"test/agl\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 40s\n",
      "AutoGluon will save models to \"test/agl/\"\n",
      "AutoGluon Version:  0.8.2\n",
      "Python Version:     3.8.18\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #38~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Thu Nov  2 18:01:13 UTC 2\n",
      "Disk Space Avail:   106.95 GB / 483.95 GB (22.1%)\n",
      "Train Data Rows:    214\n",
      "Train Data Columns: 9\n",
      "Label Column: Type\n",
      "Preprocessing data ...\n",
      "Warning: Updated label_count_threshold from 10 to 9 to avoid cutting too many classes.\n",
      "Train Data Class Count: 6\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    27760.9 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['RI', 'Na', 'Mg', 'Al', 'Si', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 9 | ['RI', 'Na', 'Mg', 'Al', 'Si', ...]\n",
      "\t0.0s = Fit runtime\n",
      "\t9 features in original data used to generate 9 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.02 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.03s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 171, Val Rows: 43\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': {},\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, 'GBMLarge'],\n",
      "\t'CAT': {},\n",
      "\t'XGB': {},\n",
      "\t'FASTAI': {},\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models ...\n",
      "Hyperparameter tuning model: KNeighborsUnif ... Tuning model for up to 2.77s of the 39.97s of remaining time.\n",
      "Warning: Exception caused KNeighborsUnif to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: KNeighborsDist ... Tuning model for up to 2.77s of the 39.97s of remaining time.\n",
      "Warning: Exception caused KNeighborsDist to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: NeuralNetFastAI ... Tuning model for up to 2.77s of the 39.97s of remaining time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Exception caused NeuralNetFastAI to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 336, in initialize\n",
      "    hyperparameter_tune_kwargs[\"scheduler\"], hyperparameter_tune_kwargs[\"scheduler\"]\n",
      "KeyError: 'scheduler'\n",
      "'scheduler'\n",
      "Hyperparameter tuning model: LightGBMXT ... Tuning model for up to 2.77s of the 39.81s of remaining time.\n",
      "Warning: Exception caused LightGBMXT to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: LightGBM ... Tuning model for up to 2.77s of the 39.81s of remaining time.\n",
      "Warning: Exception caused LightGBM to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: RandomForestGini ... Tuning model for up to 2.77s of the 39.81s of remaining time.\n",
      "Warning: Exception caused RandomForestGini to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: RandomForestEntr ... Tuning model for up to 2.77s of the 39.8s of remaining time.\n",
      "Warning: Exception caused RandomForestEntr to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: CatBoost ... Tuning model for up to 2.77s of the 39.8s of remaining time.\n",
      "Warning: Exception caused CatBoost to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: ExtraTreesGini ... Tuning model for up to 2.77s of the 39.8s of remaining time.\n",
      "Warning: Exception caused ExtraTreesGini to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: ExtraTreesEntr ... Tuning model for up to 2.77s of the 39.8s of remaining time.\n",
      "Warning: Exception caused ExtraTreesEntr to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: XGBoost ... Tuning model for up to 2.77s of the 39.8s of remaining time.\n",
      "Warning: Exception caused XGBoost to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 489, in initialize\n",
      "    hyperparameter_tune_kwargs = scheduler_factory(hyperparameter_tune_kwargs, num_trials=num_trials, nthreads_per_trial=\"auto\", ngpus_per_trial=\"auto\")\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/scheduler/scheduler_factory.py\", line 70, in scheduler_factory\n",
      "    raise ValueError(f\"Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {hyperparameter_tune_kwargs}\")\n",
      "ValueError: Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Required key 'scheduler' is not present in hyperparameter_tune_kwargs: {'num_trials': 10}\n",
      "Hyperparameter tuning model: NeuralNetTorch ... Tuning model for up to 2.77s of the 39.8s of remaining time.\n",
      "Warning: Exception caused NeuralNetTorch to fail during hyperparameter tuning... Skipping this model.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/trainer/abstract_trainer.py\", line 2018, in _train_single_full\n",
      "    hpo_models, hpo_results = model.hyperparameter_tune(\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/models/abstract/abstract_model.py\", line 1376, in hyperparameter_tune\n",
      "    hpo_executor.initialize(hyperparameter_tune_kwargs, default_num_trials=default_num_trials, time_limit=time_limit)\n",
      "  File \"/home/max/miniconda3/envs/AutoML/lib/python3.8/site-packages/autogluon/core/hpo/executors.py\", line 336, in initialize\n",
      "    hyperparameter_tune_kwargs[\"scheduler\"], hyperparameter_tune_kwargs[\"scheduler\"]\n",
      "KeyError: 'scheduler'\n",
      "'scheduler'\n",
      "Fitting model: LightGBMLarge ... Training model for up to 2.77s of the 39.8s of remaining time.\n",
      "\t0.7907\t = Validation score   (accuracy)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 39.97s of the 38.48s of remaining time.\n",
      "\t0.7907\t = Validation score   (accuracy)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 1.53s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"test/agl/\")\n"
     ]
    }
   ],
   "source": [
    "agl = AutoMLWrapper('autogluon')\n",
    "agl.SetOutputDirectory('test/agl')\n",
    "if 1:\n",
    "    agl.Train(data=df, target_column='Type',\n",
    "       task_type='classification',\n",
    "       data_type='tabular',\n",
    "       problem_type='multiclass',\n",
    "       hyperparameters=user_hp\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "akr = AutoMLWrapper('autokeras')\n",
    "akr.SetOutputDirectory('test/akr')\n",
    "if 0:\n",
    "    akr.Train(data=df, target_column='Type',\n",
    "        task_type='classification',\n",
    "        data_type='tabular',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters=user_hp\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

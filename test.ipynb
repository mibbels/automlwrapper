{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "#### Klassen protecten\n",
    "```\n",
    "import AutoMLWrapper.automlwrapper as aw\n",
    "aw.Configuration.Configuration\n",
    "```\n",
    "\n",
    "#### Erweiterung um Bibliotheken\n",
    "-  @__library.setter\n",
    "    - a) Global/GlobalConfig.yaml\n",
    "        - lib-names\n",
    "        - type mappings\n",
    "    - b) directory durchsuchen \n",
    "- import in AutoMLWrapper anpassen\n",
    "- SEDAR automl.py config locations anpassen\n",
    "\n",
    "### custom proprocessing\n",
    "- typen checken\n",
    "- die wrapper könnten property methods implementieren, die die Rückgabe eines festen samples prüfen\n",
    "\n",
    "### custom parameters\n",
    "\n",
    "\n",
    "### 2+ problem types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "from AutoMLWrapper.tests import DataSamples\n",
    "\n",
    "#from automlwrapper import AutoMLWrapper\n",
    "from AutoMLWrapper.automlwrapper import AutoMLWrapper\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "RUN_ALL = 0\n",
    "UPLOAD_ALL = 0\n",
    "\n",
    "RUN_KERAS = 0\n",
    "UPLOAD_KERAS = 0\n",
    "\n",
    "RUN_SKLEARN = 0\n",
    "UPLOAD_SKLEARN = 0\n",
    "\n",
    "RUN_GLUON = 0\n",
    "UPLOAD_GLUON = 0\n",
    "\n",
    "user_hp = {'epochs':20, 'time_limit': 360, 'memory_limit':7000, 'testtest': 123, 'num_trials': 4,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "MLFLOW = 0\n",
    "\n",
    "if MLFLOW:\n",
    "    \n",
    "    # #experiment_id = mlflow.create_experiment('test_automl', artifact_location='/home/mibbels/sedar-masterarbeit/sedar/sedar/automl/tmp/artifacts')\n",
    "    \n",
    "    experiment_id = 5\n",
    "    remote_server_uri = \"http://127.0.0.1:6798\"\n",
    "    mlflow.set_tracking_uri(remote_server_uri) \n",
    "    mlflow.set_experiment(experiment_id=experiment_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\" Bilddaten \"\"\"\n",
    "#mnist_byte_df = DataSamples.create_mnist_bytearray_df(label_col='label', n_samples=-1)\n",
    "shopee_path_df = DataSamples.create_shopee_df(is_bytearray = False, n_samples=-1)\n",
    "#mnist_tp = DataSamples.create_mnist_tuple(n_samples=-1)\n",
    "#leaf_df = DataSamples.create_leaf_df(n_samples=-1)\n",
    "\n",
    "coco_df = DataSamples.create_coco_motorbike_df(n_samples=-1)\n",
    "\n",
    "\"\"\" Textdaten \"\"\"\n",
    "#sentiment_df = DataSamples.create_sentiment_treebank_df(n_samples=-1)\n",
    "mloc_df = DataSamples.create_mloc_df(n_samples=-1)\n",
    "\n",
    "\"\"\" Tabellendaten \"\"\"\n",
    "glass_df = DataSamples.create_glass_df()\n",
    "\n",
    "\"\"\" Timeseries \"\"\"\n",
    "m4_df = DataSamples.create_m4_df(n_samples=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "coco_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ask = AutoMLWrapper('autosklearn')\n",
    "ask.SetOutputDirectory('test/ask/2')\n",
    "\n",
    "if RUN_ALL or RUN_SKLEARN:\n",
    "    ask.Train(\n",
    "        data=mnist_byte_df,\n",
    "        target_column='Type',\n",
    "        task_type='classification',\n",
    "        data_type='tabular',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters=user_hp\n",
    "    )\n",
    "\n",
    "\n",
    "if UPLOAD_ALL or UPLOAD_SKLEARN:\n",
    "    print(ask.Output())\n",
    "    ask.MlflowUploadBest({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "agl = AutoMLWrapper('autogluon')\n",
    "agl.SetOutputDirectory('test/agl/8')\n",
    "\n",
    "if RUN_ALL or RUN_GLUON: \n",
    "    agl.Train(\n",
    "        data=mnist_byte_df,\n",
    "        target_column='label',\n",
    "        data_type='image',\n",
    "        task_type='zero-shot-classification',        \n",
    "        problem_type='multiclass',\n",
    "        hyperparameters=user_hp\n",
    "   )\n",
    "    \n",
    "if UPLOAD_ALL or UPLOAD_GLUON:\n",
    "    print(agl.Output())\n",
    "    agl.MlflowUploadBest({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "akr = AutoMLWrapper('autokeras')\n",
    "akr.SetOutputDirectory('test/akr/1')\n",
    "\n",
    "if RUN_ALL or RUN_KERAS:\n",
    "    akr.Train(data=df_mnist, target_column='Type',\n",
    "        task_type='classification',\n",
    "        data_type='image',\n",
    "        problem_type='multiclass',\n",
    "        hyperparameters=user_hp\n",
    "    )\n",
    "\n",
    "if UPLOAD_ALL or UPLOAD_KERAS:\n",
    "    print(akr.Output())\n",
    "    akr.MlflowUploadBest({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLFlow\n",
    "~/miniconda3/envs/automl_env/bin/pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if MLFLOW:\n",
    "    df = df_glass.drop(columns=['Type'])\n",
    "    logged_model = 'runs:/a0337b9ecfe84e99b59ff3a9639f1ef6/model'\n",
    "    loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "    #loaded_model.predict(test_data_byte)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEDAR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader TODO\n",
    "- sedar api raw sourcedata\n",
    "- sedar api get_all_images (image metadata)\n",
    "\n",
    "- query_sourcedata nur structured\n",
    "    - image\n",
    "    - unstructured\n",
    "    - semistructured\n",
    "\n",
    "- keras format\n",
    "\n",
    "# Ingestion\n",
    "- metadaten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 15:31:36.522047: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-21 15:31:36.581235: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-21 15:31:36.582293: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-21 15:31:37.623767: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/mibbels/miniconda3/envs/automl_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend\n"
     ]
    }
   ],
   "source": [
    "from sedarapi import SedarAPI\n",
    "from AutoMLWrapper.automlwrapper.SedarDataLoader import SedarDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SedarAPI-Logger:Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:SedarAPI-Logger:Component Apache Jena Fuseki is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Jupyter - SingleUser is not alive.\n",
      "WARNING:SedarAPI-Logger:Component WebVOWL is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Ingestion - Service is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Schema & Metadata - Service is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Continuation - Service is not alive.\n",
      "WARNING:SedarAPI-Logger:Component Profiling - Service is not alive.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sedarapi.user.User at 0x7f8b34100a00>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_url = \"http://192.168.220.107:5000\"\n",
    "email = \"admin\"\n",
    "password = \"admin\"\n",
    "\n",
    "sedar = SedarAPI(base_url)\n",
    "sedar.connection.logger.setLevel(\"INFO\")\n",
    "sedar.login(email, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace_id = '13b4787c3e454649aa05a4cd680edc37'\n",
    "dataset_id = '324ea420125d4167a76151b62368c4ad'\n",
    "\n",
    "# 986f2e837ca44f3e8c0ee7d2dc0c4287  - glass\n",
    "# b5b74391e41e4634a54d5cffa059663b - coco_22_train_v1 \n",
    "# 324ea420125d4167a76151b62368c4ad - gitter_train_v1\n",
    "# 513c6b1ee46b478c8e0925a098d2f387  - test classification 1 img each class\n",
    "\n",
    "DataLoader = SedarDataLoader(sedar)\n",
    "#loc = DataLoader.query_data(workspace_id, dataset_id, file_save_location='./data/sedar_raw/test')\n",
    "#X, y, mapping = DataLoader.zip_to_class_np_keras(loc[0], './data/sedar_raw/test/test_coco')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.scripts import tabular_metrics\n",
    "\n",
    "if 0:\n",
    "    DataLoader.CAAFEFeatureEngineering(\n",
    "        workspace_id, \n",
    "        '986f2e837ca44f3e8c0ee7d2dc0c4287', \n",
    "        file_save_location='./data/sedar_raw/test',\n",
    "        data_type='tabular',\n",
    "        problem_type='classification',\n",
    "        target='Type',\n",
    "        dataset_description='No description',\n",
    "        iterations=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: the data has been written to: ./data/sedar_raw/test/coco_22_balanced.zip\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "max() arg is an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDataLoader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAAFEFeatureEngineering\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkspace_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mb5b74391e41e4634a54d5cffa059663b\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfile_save_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./data/sedar_raw/test\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msegmentation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_description\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNo description\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sedar-masterarbeit/sedar/sedar/automl/AutoMLWrapper/automlwrapper/SedarDataLoader.py:408\u001b[0m, in \u001b[0;36mSedarDataLoader.CAAFEFeatureEngineering\u001b[0;34m(self, workspace_id, dataset_id, file_save_location, data_type, problem_type, target, dataset_description, model, iterations)\u001b[0m\n\u001b[1;32m    401\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzip_to_segmentation_np(loc[\u001b[38;5;241m0\u001b[39m], file_save_location\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_unzipped\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    403\u001b[0m caafe_clf \u001b[38;5;241m=\u001b[39m CAAFEImageSegmentor(\n\u001b[1;32m    404\u001b[0m     llm_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    405\u001b[0m     iterations\u001b[38;5;241m=\u001b[39miterations\n\u001b[1;32m    406\u001b[0m     )\n\u001b[0;32m--> 408\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mcaafe_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperformance_before_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    409\u001b[0m iou \u001b[38;5;241m=\u001b[39m iou \u001b[38;5;241m=\u001b[39m jaccard_score(y\u001b[38;5;241m.\u001b[39mflatten(), pred\u001b[38;5;241m.\u001b[39mflatten(), average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIoU before CAAFE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miou\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[0;32m~/sedar-masterarbeit/sedar/sedar/automl/CAAFE/caafe/segmentation_wrapper.py:521\u001b[0m, in \u001b[0;36mCAAFEImageSegmentor.performance_before_run\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mperformance_before_run\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[1;32m    520\u001b[0m     num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y))\n\u001b[0;32m--> 521\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_classifier \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimple_unet_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43miou\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_classifier\u001b[38;5;241m.\u001b[39mfit(X, to_categorical(y, num_classes), epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    524\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[0;32m~/sedar-masterarbeit/sedar/sedar/automl/CAAFE/caafe/segmentation_wrapper.py:425\u001b[0m, in \u001b[0;36mCAAFEImageSegmentor.simple_unet_model\u001b[0;34m(self, input_shape, num_classes, metric)\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m metric \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miou\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 425\u001b[0m     metric \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMeanIoU\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    427\u001b[0m c1 \u001b[38;5;241m=\u001b[39m Conv2D(\u001b[38;5;241m16\u001b[39m, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhe_normal\u001b[39m\u001b[38;5;124m'\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m)(inputs)\n\u001b[1;32m    428\u001b[0m p1 \u001b[38;5;241m=\u001b[39m MaxPooling2D((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m))(c1)\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/keras/dtensor/utils.py:144\u001b[0m, in \u001b[0;36minject_mesh.<locals>._wrap_function\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mesh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     instance\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;241m=\u001b[39m mesh\n\u001b[0;32m--> 144\u001b[0m \u001b[43minit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/keras/metrics/iou_metrics.py:510\u001b[0m, in \u001b[0;36mMeanIoU.__init__\u001b[0;34m(self, num_classes, name, dtype, ignore_class, sparse_y_true, sparse_y_pred, axis)\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;129m@dtensor_utils\u001b[39m\u001b[38;5;241m.\u001b[39minject_mesh\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m     axis: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    508\u001b[0m ):\n\u001b[1;32m    509\u001b[0m     target_class_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(num_classes))\n\u001b[0;32m--> 510\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_class_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_class_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse_y_true\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_y_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43msparse_y_pred\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msparse_y_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/keras/dtensor/utils.py:144\u001b[0m, in \u001b[0;36minject_mesh.<locals>._wrap_function\u001b[0;34m(instance, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mesh \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     instance\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;241m=\u001b[39m mesh\n\u001b[0;32m--> 144\u001b[0m \u001b[43minit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/keras/metrics/iou_metrics.py:256\u001b[0m, in \u001b[0;36mIoU.__init__\u001b[0;34m(self, num_classes, target_class_ids, name, dtype, ignore_class, sparse_y_true, sparse_y_pred, axis)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;129m@dtensor_utils\u001b[39m\u001b[38;5;241m.\u001b[39minject_mesh\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m     axis: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    246\u001b[0m ):\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    248\u001b[0m         name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    249\u001b[0m         num_classes\u001b[38;5;241m=\u001b[39mnum_classes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    255\u001b[0m     )\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtarget_class_ids\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m num_classes:\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    258\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget class id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(target_class_ids)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    259\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis out of range, which is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    260\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m0\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    261\u001b[0m         )\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_class_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(target_class_ids)\n",
      "\u001b[0;31mValueError\u001b[0m: max() arg is an empty sequence"
     ]
    }
   ],
   "source": [
    "DataLoader.CAAFEFeatureEngineering(\n",
    "    workspace_id, \n",
    "    '324ea420125d4167a76151b62368c4ad', \n",
    "    file_save_location='./data/sedar_raw/test',\n",
    "    data_type='image',\n",
    "    problem_type='segmentation',\n",
    "    dataset_description='No description',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = DataLoader.zip_to_segmentation_np_keras(loc[0], './data/sedar_raw/test/test_seg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-21 11:42:06.220877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-21 11:42:07.431850: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from CAAFE.caafe import CAAFEImageClassifier, CAAFEImageSegmentor\n",
    "from sklearn.metrics import accuracy_score\n",
    "import openai\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    import keras\n",
    "\n",
    "    cifar10 = keras.datasets.cifar10\n",
    "    (X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "    X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "    # If you want to use the entire dataset as X and y\n",
    "    X = np.concatenate((X_train, X_test), axis=0, dtype=np.float32)\n",
    "    y = np.concatenate((y_train, y_test), axis=0, dtype=np.float32)\n",
    "\n",
    "    #X = X.reshape(X.shape[0], 28, 28, 1)\n",
    "    X = X[:1000]\n",
    "    y = y[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 2.2672 - accuracy: 0.1530\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 2.0202 - accuracy: 0.2780\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.8089 - accuracy: 0.3480\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - 1s 16ms/step - loss: 1.6526 - accuracy: 0.4250\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 1s 17ms/step - loss: 1.5424 - accuracy: 0.4510\n",
      "32/32 [==============================] - 0s 5ms/step\n",
      "Accuracy before CAAFE 0.491\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "*Dataset description:*\n",
       " This is the CIFAR10 dataset."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "*Iteration 1*\n",
       "```python\n",
       "\n",
       "# Image Augmentation: Horizontal Flip\n",
       "# Usefulness: This transformation can increase the size of the dataset and introduce a form of positional variance. It is especially useful for the CIFAR10 dataset, where the orientation of the image does not necessarily define its class.\n",
       "from keras.preprocessing.image import ImageDataGenerator\n",
       "\n",
       "datagen = ImageDataGenerator(horizontal_flip=True)\n",
       "datagen.fit(X)\n",
       "\n",
       "# Create a new variable to hold the augmented images\n",
       "X_augmented = []\n",
       "\n",
       "# Generate augmented images\n",
       "for x in X:\n",
       "    for x_aug in datagen.flow(x.reshape((1,) + x.shape), batch_size=1):\n",
       "        X_augmented.append(x_aug[0])\n",
       "        break  # we only want one augmented image per original image, so stop the loop\n",
       "\n",
       "# Convert the list of augmented images to a numpy array\n",
       "X_augmented = np.array(X_augmented)\n",
       "\n",
       "# Concatenate the original and augmented datasets\n",
       "X = np.concatenate((X, X_augmented))\n",
       "y = np.concatenate((y, y))  # extend y accordingly\n",
       "\n",
       "```\n",
       "Performance before adding features ROC 0.340, ACC 0.837.\n",
       "Performance after adding features ROC 0.365, ACC 0.841.\n",
       "Improvement ROC 0.025, ACC 0.004.\n",
       "The code was executed and changes to the data were kept.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "*Iteration 2*\n",
       "```python\n",
       "\n",
       "# Image Augmentation: Rotation\n",
       "# Usefulness: This transformation can introduce rotational variance to the dataset. It can help the model to generalize better by learning to recognize objects in different orientations.\n",
       "from keras.preprocessing.image import ImageDataGenerator\n",
       "\n",
       "datagen = ImageDataGenerator(rotation_range=20) # Rotate images by 20 degrees\n",
       "datagen.fit(X)\n",
       "\n",
       "# Create a new variable to hold the augmented images\n",
       "X_augmented = []\n",
       "\n",
       "# Generate augmented images\n",
       "for x in X:\n",
       "    for x_aug in datagen.flow(x.reshape((1,) + x.shape), batch_size=1):\n",
       "        X_augmented.append(x_aug[0])\n",
       "        break  # we only want one augmented image per original image, so stop the loop\n",
       "\n",
       "# Convert the list of augmented images to a numpy array\n",
       "X_augmented = np.array(X_augmented)\n",
       "\n",
       "# Concatenate the original and augmented datasets\n",
       "X = np.concatenate((X, X_augmented))\n",
       "y = np.concatenate((y, y))  # extend y accordingly\n",
       "\n",
       "```\n",
       "Performance before adding features ROC 0.383, ACC 0.844.\n",
       "Performance after adding features ROC 0.427, ACC 0.842.\n",
       "Improvement ROC 0.045, ACC -0.002.\n",
       "The code was executed and changes to the data were kept.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "*Iteration 3*\n",
       "```python\n",
       "\n",
       "# Image Augmentation: Zoom\n",
       "# Usefulness: Zooming can help the model to recognize objects of different scales. This can be very useful for the CIFAR10 dataset where objects can appear in different sizes.\n",
       "from keras.preprocessing.image import ImageDataGenerator\n",
       "\n",
       "datagen = ImageDataGenerator(zoom_range=0.2) # Zoom in on images by 20%\n",
       "datagen.fit(X)\n",
       "\n",
       "# Create a new variable to hold the augmented images\n",
       "X_augmented = []\n",
       "\n",
       "# Generate augmented images\n",
       "for x in X:\n",
       "    for x_aug in datagen.flow(x.reshape((1,) + x.shape), batch_size=1):\n",
       "        X_augmented.append(x_aug[0])\n",
       "        break  # we only want one augmented image per original image, so stop the loop\n",
       "\n",
       "# Convert the list of augmented images to a numpy array\n",
       "X_augmented = np.array(X_augmented)\n",
       "\n",
       "# Concatenate the original and augmented datasets\n",
       "X = np.concatenate((X, X_augmented))\n",
       "y = np.concatenate((y, y))  # extend y accordingly\n",
       "\n",
       "```\n",
       "Performance before adding features ROC 0.431, ACC 0.846.\n",
       "Performance after adding features ROC 0.439, ACC 0.845.\n",
       "Improvement ROC 0.007, ACC -0.002.\n",
       "The code was executed and changes to the data were kept.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "250/250 [==============================] - 5s 16ms/step - loss: 1.7260 - accuracy: 0.3719\n",
      "Epoch 2/5\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 1.1567 - accuracy: 0.5861\n",
      "Epoch 3/5\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.7956 - accuracy: 0.7261\n",
      "Epoch 4/5\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.4869 - accuracy: 0.8404\n",
      "Epoch 5/5\n",
      "250/250 [==============================] - 4s 16ms/step - loss: 0.2802 - accuracy: 0.9181\n",
      "250/250 [==============================] - 1s 5ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [8000, 1000]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     12\u001b[0m caafe_clf\u001b[38;5;241m.\u001b[39mfit_images(\n\u001b[1;32m     13\u001b[0m     X,\n\u001b[1;32m     14\u001b[0m     y,\n\u001b[1;32m     15\u001b[0m     dataset_description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the CIFAR10 dataset.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m     )\n\u001b[1;32m     18\u001b[0m pred \u001b[38;5;241m=\u001b[39m caafe_clf\u001b[38;5;241m.\u001b[39mpredict(X)\n\u001b[0;32m---> 19\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy after CAAFE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m X, y \u001b[38;5;241m=\u001b[39m caafe_clf\u001b[38;5;241m.\u001b[39mapply_code(X, y)\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:202\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 202\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:83\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m     85\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n",
      "File \u001b[0;32m~/miniconda3/envs/automl_env/lib/python3.8/site-packages/sklearn/utils/validation.py:319\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    317\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths])\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [8000, 1000]"
     ]
    }
   ],
   "source": [
    "#model = \"gpt-3.5-turbo\"\n",
    "model = \"gpt-4\"\n",
    "caafe_clf = CAAFEImageClassifier(llm_model=model,\n",
    "                                 iterations=3,\n",
    "                                 )\n",
    "\n",
    "pred = caafe_clf.performance_before_run(X, y)\n",
    "acc = accuracy_score(pred, y)\n",
    "print(f'Accuracy before CAAFE {acc}')\n",
    "\n",
    "\n",
    "caafe_clf.fit_images(\n",
    "    X,\n",
    "    y,\n",
    "    dataset_description=\"This is the CIFAR10 dataset.\"\n",
    "    )\n",
    "\n",
    "pred = caafe_clf.predict(X)\n",
    "acc = accuracy_score(pred, y)\n",
    "print(f'Accuracy after CAAFE {acc}')\n",
    "\n",
    "X, y = caafe_clf.apply_code(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 10s 5ms/step\n",
      "Accuracy after CAAFE 0.76725\n"
     ]
    }
   ],
   "source": [
    "_, y = caafe_clf.apply_code(X, y)\n",
    "pred = caafe_clf.predict(X)\n",
    "acc = accuracy_score(pred, y)\n",
    "print(f'Accuracy after CAAFE {acc}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "if 0:\n",
    "    ws = sedar.get_workspace('13b4787c3e454649aa05a4cd680edc37')\n",
    "    dataset = ws.get_dataset('986f2e837ca44f3e8c0ee7d2dc0c4287')\n",
    "    \n",
    "    # try:\n",
    "    #     success = dataset.delete()\n",
    "    #     if success:\n",
    "    #         print(\"Dataset deleted successfully.\")\n",
    "    # except Exception as e:\n",
    "    #     print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-22 19:31:53.916724: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-22 19:31:53.976227: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-22 19:31:53.976863: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-22 19:31:55.166397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Using TensorFlow backend\n",
      "2024-01-22 19:32:14.355027: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [500]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2024-01-22 19:32:14.355507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [500]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2024-01-22 19:32:14.465914: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [500]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2024-01-22 19:32:14.466200: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [500]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "vanilla           |vanilla           |image_block_1/block_type\n",
      "True              |True              |image_block_1/normalize\n",
      "False             |False             |image_block_1/augment\n",
      "3                 |3                 |image_block_1/conv_block_1/kernel_size\n",
      "1                 |1                 |image_block_1/conv_block_1/num_blocks\n",
      "2                 |2                 |image_block_1/conv_block_1/num_layers\n",
      "True              |True              |image_block_1/conv_block_1/max_pooling\n",
      "False             |False             |image_block_1/conv_block_1/separable\n",
      "0.25              |0.25              |image_block_1/conv_block_1/dropout\n",
      "32                |32                |image_block_1/conv_block_1/filters_0_0\n",
      "64                |64                |image_block_1/conv_block_1/filters_0_1\n",
      "flatten           |flatten           |classification_head_1/spatial_reduction_1/reduction_type\n",
      "0.5               |0.5               |classification_head_1/dropout\n",
      "adam              |adam              |optimizer\n",
      "0.001             |0.001             |learning_rate\n",
      "\n",
      "2024-01-22 19:32:18.200999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_36' with dtype float and shape [10,10]\n",
      "\t [[{{node Placeholder/_36}}]]\n",
      "2024-01-22 19:32:18.201483: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype uint8 and shape [500,28,28]\n",
      "\t [[{{node Placeholder/_15}}]]\n",
      "2024-01-22 19:32:18.418613: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_33' with dtype resource\n",
      "\t [[{{node Placeholder/_33}}]]\n",
      "2024-01-22 19:32:18.419098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [500]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - ETA: 0s - loss: 1.8533 - accuracy: 0.43272024-01-22 19:32:19.920260: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [500]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2024-01-22 19:32:19.920836: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype uint8 and shape [500,28,28]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "13/13 [==============================] - 2s 60ms/step - loss: 1.8533 - accuracy: 0.4327 - val_loss: 1.0744 - val_accuracy: 0.7976\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 0.6433 - accuracy: 0.8462 - val_loss: 0.6042 - val_accuracy: 0.7857\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 1s 41ms/step - loss: 0.4297 - accuracy: 0.8582 - val_loss: 0.5041 - val_accuracy: 0.8333\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 0.2909 - accuracy: 0.8990 - val_loss: 0.5522 - val_accuracy: 0.8452\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 1s 39ms/step - loss: 0.2097 - accuracy: 0.9327 - val_loss: 0.4917 - val_accuracy: 0.8452\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 39ms/step - loss: 0.1324 - accuracy: 0.9615 - val_loss: 0.4965 - val_accuracy: 0.8810\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.1066 - accuracy: 0.9736 - val_loss: 0.5119 - val_accuracy: 0.8571\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 38ms/step - loss: 0.0720 - accuracy: 0.9880 - val_loss: 0.5190 - val_accuracy: 0.8690\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 37ms/step - loss: 0.0510 - accuracy: 0.9904 - val_loss: 0.6097 - val_accuracy: 0.8690\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 1s 42ms/step - loss: 0.0431 - accuracy: 0.9904 - val_loss: 0.6043 - val_accuracy: 0.8690\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 1s 47ms/step - loss: 0.0440 - accuracy: 0.9880 - val_loss: 0.6165 - val_accuracy: 0.8452\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 1s 48ms/step - loss: 0.0328 - accuracy: 0.9904 - val_loss: 0.6213 - val_accuracy: 0.8452\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.0390 - accuracy: 0.9808 - val_loss: 0.5401 - val_accuracy: 0.8452\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 1s 50ms/step - loss: 0.0214 - accuracy: 0.9952 - val_loss: 0.6271 - val_accuracy: 0.8571\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 1s 45ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 0.6623 - val_accuracy: 0.8452\n",
      "Trial 1 Complete [00h 00m 12s]\n",
      "val_loss: 0.4917336404323578\n",
      "\n",
      "Best val_loss So Far: 0.4917336404323578\n",
      "Total elapsed time: 00h 00m 12s\n",
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "resnet            |vanilla           |image_block_1/block_type\n",
      "True              |True              |image_block_1/normalize\n",
      "True              |False             |image_block_1/augment\n",
      "True              |None              |image_block_1/image_augmentation_1/horizontal_flip\n",
      "True              |None              |image_block_1/image_augmentation_1/vertical_flip\n",
      "0                 |None              |image_block_1/image_augmentation_1/contrast_factor\n",
      "0                 |None              |image_block_1/image_augmentation_1/rotation_factor\n",
      "0.1               |None              |image_block_1/image_augmentation_1/translation_factor\n",
      "0                 |None              |image_block_1/image_augmentation_1/zoom_factor\n",
      "False             |None              |image_block_1/res_net_block_1/pretrained\n",
      "resnet50          |None              |image_block_1/res_net_block_1/version\n",
      "True              |None              |image_block_1/res_net_block_1/imagenet_size\n",
      "global_avg        |flatten           |classification_head_1/spatial_reduction_1/reduction_type\n",
      "0                 |0.5               |classification_head_1/dropout\n",
      "adam              |adam              |optimizer\n",
      "0.001             |0.001             |learning_rate\n",
      "\n",
      "2024-01-22 19:32:32.355060: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_5' with dtype uint8 and shape [500]\n",
      "\t [[{{node Placeholder/_5}}]]\n",
      "2024-01-22 19:32:32.355518: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_34' with dtype int32\n",
      "\t [[{{node Placeholder/_34}}]]\n",
      "2024-01-22 19:32:32.507808: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_33' with dtype resource\n",
      "\t [[{{node Placeholder/_33}}]]\n",
      "2024-01-22 19:32:32.508330: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_36' with dtype float and shape [10,10]\n",
      "\t [[{{node Placeholder/_36}}]]\n",
      "Epoch 1/20\n",
      " 7/13 [===============>..............] - ETA: 46s - loss: 3.5543 - accuracy: 0.2009^C\n"
     ]
    }
   ],
   "source": [
    "!cd ./AutoMLWrapper/tests && python3 -m unittest TestAutoMLWrapper.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
